# DreamBig UX Testing Documentation

**By** **Kanna Srilakshmananan** **Hazratomar Hassanzada** **Cynthia Yi Min Chee**

## Table of Contents

- [DreamBig UX Testing Documentation](#dreambig-ux-testing-documentation)
  - [Table of Contents](#table-of-contents)
  - [Introduction](#introduction)
  - [Testing Methodology](#testing-methodology)
  - [Method 1: In-Person Testing](#method-1-in-person-testing)
  - [The participants](#the-participants)
  - [The facilitators](#the-facilitators)
  - [Recruiting participants](#recruiting-participants)
    - [A. Number of participants](#a-number-of-participants)
  - [Time](#time)
  - [Budget](#budget)
  - [Sample size](#sample-size)
    - [B. Participant Group](#b-participant-group)
    - [C. How to reach out to recruit participants](#c-how-to-reach-out-to-recruit-participants)
  - [Conducting the tests](#conducting-the-tests)
  - [Method 2: Online Testing](#method-2-online-testing)
  - [A. Survey goals](#a-survey-goals)
    - [User Satisfaction](#user-satisfaction)
    - [User preferences](#user-preferences)
    - [Usability Issues](#usability-issues)
    - [Additional features](#additional-features)
    - [B. Survey structure](#b-survey-structure)
    - [Design](#design)
    - [Usability](#usability)
    - [User Need Assessment](#user-need-assessment)
    - [C. Question design](#c-question-design)
    - [Simplicity](#simplicity)
    - [Topic-Specific](#topic-specific)
    - [Rating Scales](#rating-scales)
    - [Logical Flow](#logical-flow)
    - [D. Survey distribution](#d-survey-distribution)
    - [E. Data Collection](#e-data-collection)
  - [Consent and Ethical Considerations](#consent-and-ethical-considerations)
  - [Consent](#consent)
  - [Ethical Considerations](#ethical-considerations)
  - [Data Collection, Analysis and Visualization](#data-collection-analysis-and-visualization)
  - [A. Data Storage](#a-data-storage)
  - [B. Data Analysis](#b-data-analysis)
    - [Cleaning Data](#cleaning-data)
    - [Analysis](#analysis)
  - [C. Visualization Tools](#c-visualization-tools)
    - [Microsoft Excel/Google Spreadsheet](#microsoft-excelgoogle-spreadsheet)
    - [Google data studio](#google-data-studio)
    - [Canva](#canva)
  - [D. Data Interpretation](#d-data-interpretation)
    - [Key Trends](#key-trends)
    - [Cross-comparison of data](#cross-comparison-of-data)
    - [Interpreting Qualitative data](#interpreting-qualitative-data)
  - [E. Communicating Results](#e-communicating-results)
    - [Infographics/Posters](#infographicsposters)
    - [PowerPoint Presentation](#powerpoint-presentation)
    - [Detailed report of the findings](#detailed-report-of-the-findings)
  - [Conclusion](#conclusion)

## Introduction

DreamBig is an ongoing project under Thoth Tech aimed at enhancing students\' professional identity
by gearing them for graduation and assisting in a smooth transition. The goal of DreamBig is to
facilitate professional development improve employability of students.

At the time of creation of this report, DreamBig is still in developmental stages. The goal of this
report is to outline the plans and procedures for testing to be carried out in preparation for the
release of the DreamBig prototype.

UX Testing is essential to evaluate and assess the functionality and design of the prototype to
ensure it meets the requirements of users. The prototype is evaluated based on several aspects, and
the feedback is incorporated into improving the prototype.

The UX Testing team's aim is to discover problems in the design and usability of the DreamBig
system. We aim to obtain valuable data through surveys and in person testing, thus, improving the
overall user experience of the product. All gaps and issues identified will be reported back to the
DreamBig development to improve the final product. The following report will explore the various
testing strategies we plan to implement.

## Testing Methodology

UX Testing can be done in several ways. Here, we propose two ways to conduct the testing of the
DreamBig system -- **In-person** and **Online.**

## Method 1: In-Person Testing

In-Person testing involves inviting participants to test the prototype **in-person**. The
participant will be in the testing location with one or several facilitators.

## The participants

As the target users for DreamBig are Deakin students, they will be the focus group of participants
for in-person testing. At the moment, DreamBig is mainly targeted towards IT students. As such, we
will focus on this group with the possibility of expanding it to other faculties in the future.

## The facilitators

The facilitators will comprise testers from the DreamBig team. They may be from a dedicated testing
team in DreamBig, but also from different teams such as Design Team, Backend Team, and so on. This
is to ensure the feedback reaches all aspects of DreamBig development.

## Recruiting participants

### A. Number of participants

At present, we are aiming for recruit **30 participants** for in-person testing, with up to **5
participants** to be tested in one session. Some factors to consider while recruiting participants
for in-person testing include:

## Time

Time constraints exist in making sure testing is completed within a trimester. Allowing for up to 5
participants to be tested at a time would increase efficiency.

## Budget

As DreamBig would be a fairly new company, budget constraints on the company will be present. We aim
to obtain voluntary participation for the testing, with the possibility of offering incentives in
the form of gift vouchers to boost participation.

## Sample size

We aim for 30 participants to ensure there is a sufficiently large sample size for feedback data
while still considering the time and budget constraints.

### B. Participant Group

While recruiting participants, as stated previously we aim to focus on Deakin IT students at
present. Should DreamBig later expand to students of other faculties, testing would then also be
expanded to include those groups of students. We also aim to ensure diversity and a wide range of
participants. Some factors to consider are:

1. **Age bracket** - Participants can be from a wide range of ages, including mature age students as
   long as they are an IT student of Deakin University.

2. **Course level** -- At the moment, we are focusing on undergraduate IT students of Deakin
   University, regardless of their year of study.

3. **Gender** -- We aim to include participants of all genders and sexual orientation. Nevertheless,
   participants can choose not to disclose this information.

4. **Student type** -- We aim to include both local and international students as long as they are
   IT students of Deakin University.

### C. How to reach out to recruit participants

**Active recruitment:** Recruitment of students required for testing can be performed by sending out
request emails through to students sourced from Deakin databases. Alternatively, approaching
students at campus is another option. Other methods of active recruitment include via email and
phone.

**Passive recruitment:** Emails can be sent out to all IT students at Deakin Universities with
invitations to participate in the testing. Alternatively, registration links can be shared by Deakin
IT staff to their students. Interested students can register via the invitation link. A listing can
also be added to Deakin's job boards (such as DeakinTALENT) with the application link.

## Conducting the tests

A. **Location:** Tests in person will be conducted at a room located at Deakin University.
Facilitators will be present to conduct the testing. Computers will be provided to the participant
to assist with the test.

B. **Methodology**: The facilitator(s) will provide a series of instructions or tasks to the
participant(s) to navigate through the DreamBig prototype. The participant(s) are also encouraged to
share their feedback and vocalise their line of thinking while navigating through the prototype. The
facilitator(s) will note down participants' feedback as well as the observations of their
performance while navigating.

C. **Data collection:** The data will be collected into an in-person data collection template
containing important points such as the prototype design, usability and user needs assessment. The
data collected would be in the form of scoring as well as user feedback.

## Method 2: Online Testing

The second type of testing, **online testing**, is to be done in the form of a survey in Google
Forms. With online testing, evaluation can be done remotely and asynchronously. Due to its greater
convenience, it can be done by more participants.

## A. Survey goals

The goal of conducting the survey is to obtain user feedback and how they rate their experience
while using the application. We aim to gather information about several aspects:

### User Satisfaction

- This refers to how much a user is satisfied overall with using the application. Aspects to
  consider are ease of use, attractiveness and visual appeal.

### User preferences

- User preferences would allow us to make changes/improvements tailored specifically to the user
  feedback. This would be extremely beneficial as a user may point out areas of improvement that the
  team may have not thought needed improvement.

### Usability Issues

- This refers to how user-friendly the application is. Aspects to consider are whether the
  application is easy to navigation, and if the application is intuitive enough that users can
  navigate around without the need of much guidance.

### Additional features

- In addition to the scoring elements in the survey, users are able to provide feedback in their own
  words and suggestions for further improving the prototype.

### B. Survey structure

Design, Usability, and User Needs Assessment are the three key components of the survey to be
considered. This structure\'s goal is to collect thorough input on all elements of the user
experience, allowing for in-depth analysis and useful insights. The survey has more than 40
questions, ensuring a complete assessment and analysis of the responses which will be beneficial for
the visualisation. Each question consists of a ranking system from 1 -- 5 points, ranging from Very
Poor to Very Good.

### Design

- This aspect focuses on the visual elements of the prototype, such as the colour schemes, theme,
  icons, fonts and so on. This is important to ensure the application is not only visual-appealing,
  but also enables ease of navigation.

### Usability

- Usability refers to the ease of use of the system. Important aspects to consider are Affordance
  (whether the system is intuitive enough to navigate through without needing a lot of guidance) and
  Accessibility (whether it accommodates various types of users with various needs).

### User Need Assessment

- The purpose of the User Needs section is to rank how well the needs of the users are met. It
  focuses on whether the use of the application helps students boost their professional development,
  and their perception of whether the application is helpful and useful to them.

### C. Question design

The survey questions are designed based on a rubric created with the three main aspects stated
previously (Design, Usability, User Needs Assessment). Each question comes with options on a scale
of 1 to 5 (Very Poor to Very Good). In addition to that, there are additional questions for any text
feedback for users to provide their own suggestions.

### Simplicity

- The questions are designed in a way to eliminate any misunderstanding or confusion, written in a
  basic, direct manner using plain terminology to mitigate any potential confusion. Technical jargon
  and complex phrases are avoided to ensure that participants can quickly understand and react to
  each question.

### Topic-Specific

- Each question emphasises on a certain component of the user experience. This enables more precise
  and in-depth input to the specific topic/section, which in turn allows for more analysis.

### Rating Scales

- Rating scales from 1 -- 5 are used to allow for more quantitative feedback to correctly capture
  participants\' thoughts and perceptions much more precisely via a scale, as opposed to a simple
  yes or no. Users can express how much they agree or are satisfied using numeric scales, from Very
  Poor to Very Good range. Towards the conclusion, there are also choices for open-ended responses
  to encourage participants to offer in-depth explanations, ideas, or examples.

### Logical Flow

- The survey\'s questions are organised in a logical and consistent order to provide a seamless
  flow. The survey is carefully designed to gather relevant items together and show them in a
  logical manner, facilitating easy survey navigation for participants.

### D. Survey distribution

The survey would be distributed in various ways. Emails could be sent to Deakin IT students with
details explaining the purposes of the testing along with a link to the survey. The survey link
could also be included in a QR code, which would be on display for students on-campus with some
DreamBig members encouraging the students to scan them and explaining their purposes. Other than
that, Deakin IT staff can be tasked with sharing the survey link with their students so that it
reaches as many IT students as possible.

### E. Data Collection

The data collected will be stored in Google Forms and accessible by the testing team. As the survey
questions are standardised, the testing team can compare the responses across all participants. In
addition to that, participants can optionally choose to provide information about their gender,
sexual orientation and ethnicity to provide an additional aspect of data analysis.

## Consent and Ethical Considerations

## Consent

Prior to beginning the testing, consent is a vital part of ethical data collection. The major points
of consent are as follows:

**Fully inform participants:** Participants, whether in-person or online, must be fully informed of
the purposes of the testing and how the data obtained will be used.

**Optional disclosure:** While certain data such as the evaluation feedback and student information
is required, participants should be offered the option to not disclose certain information should
they choose to. Such details include gender and sexual orientation.

**Voluntary participation:** Participants should be fully informed that participation in the testing
is completely voluntary. Should they choose to withdraw any time prior to completing their testing
and submitting the results, they are free to do so. However, they should also be made aware that any
information that has already been collected and submitted may remain in the system.

**Renumeration:** Participation in the testing is on a voluntary basis and as such, there is no
monetary renumeration. However, depending on available funding they may be offered gift vouchers in
exchange for their time.

**Non-disclosure:** Participants agree to maintain confidentiality and are not allowed to disclose
sensitive information regarding the application.

## Ethical Considerations

The following are ethical considerations to be taken into account while conducting the evaluation:

**Privacy issues:** Participants should be fully informed of how their information is stored and
used. Consent is obtained to ensure they are aware and agree to the usage of this information.

**Bias:** Testing should be conducted in a standardised manner for all participants. Facilitators
should deliver instructions and prompts objectively and neutrally to avoid biasing the testing as
much as possible.

**Discrimination:** No group or groups of participants should be excluded, and the tests conducted
should be the same for everybody. In addition to that, participants should be given the option to
not disclose sensitive personal information.

**Data security:** Adequate security measures should be put in place to ensure proper data
protection.

## Data Collection, Analysis and Visualization

## A. Data Storage

Data collected via in-person testing will be entered into a spreadsheet by the testing facilitator,
while data from online surveys will be stored in the database from Google Forms.

## B. Data Analysis

Data analysis is the first key step in the visualisation process and is fundamental. It requires
cleansing then analysis on the cleaned data.

### Cleaning Data

As the name suggests, after receiving the data, we must then prepare it for cleaning. This is done
to remove any possible human errors in the data. We must account for any missing or inconsistent
data.

### Analysis

After the cleaning of the data, we will then begin analysis. The survey answers will be collected in
an excel spreadsheet which will be connected to the survey. This will allow us to have access to a
range of methods used for statistical analysis, such as the mean, median and mode. If we would like
a more in-depth analysis, we may even consider standard deviations of the dataset.

Overall, the data analysis step in the visualisation process is the key first step, and without
cleansing the data, and then analysing the data we would not be able to proceed to visualisation.

## C. Visualization Tools

After the data analysis is completed, we can then go on to visually presenting the data. There are
many possible visualization tools to use. Some examples are:

### Microsoft Excel/Google Spreadsheet

Excel or Spreadsheet are both good options when it comes to built-in graphs, or analysis
capabilities. As the data would already be stored in spreadsheets, this would increase convenience.
Excel has many functions that we can use to our advantage such as IF statements, MATCH function or
FIND & FINDB functions just to name a few. These will be beneficial when it comes to comparative
analysis. The following are examples of charts available in Excel:

### Google data studio

Another tool we could use is Google's Data studio. This is an integration to excel or spreadsheet.
One thing that makes this very useful is how fluid the integration is, and just how many charts it
offers, from line graphs bar charts, it also allows us to make interactive charts as well, which
makes the visualisation much more dynamic.

### Canva

Though not specifically a visualisation tool, Canva offers a free platform to design anything from
graphics to infographics. After analysing the data and visually presenting the data through various
charts that excel offers, we will then need to make the charts much more visually appealing and more
topic specific, rather than just a simple line graph, or bar chart. Ways we could enhance the graphs
could be through various assets that canvas offers, such as logos or free to use images.

## D. Data Interpretation

After visualising the result found in the graphs, we must then now interpret this data in such a way
that it offers a logical insight into what we are aiming to achieve. The following can be applied to
help with this interpretation:

### Key Trends

Through analysing the visualisations, we aim to identify significant patterns and trends in the
survey responses. This includes understanding similarities, differences, and noteworthy outliers in
the data. We will focus on observing consistent patterns or changes across various factors and
timeframes.

### Cross-comparison of data

Cross comparison of the data through the means of using graphs such as line graphs, or bar graphs,
help to find correlation between data that may not have any relation to one another on the surface.
However, we may take this a step further by finding correlation coefficient **_r._** this would find
any correlation between the dataset, however it does not mean causation between the two variables.
Therefore, to properly find any meaningful relation between the data we must go a step further and
find the coefficient of determination R\^2. This is a measurement of how much variation one factor
is directly caused by its relation to another factor.

### Interpreting Qualitative data

Our survey also contains user feedback, which without transformation remains as qualitative.
Therefore, we must transform this data in such a way that will allow us to categorise the responses
into only small number of possible Reponses. For example, we would have only 5 responses, and then
we must interpret each individual response into one possible category. Then visualizations will be
used from the participants\' written responses and suggestions to provide a comprehensive
understanding.

Having these steps in place would allow to have a deeper insight into the data and would allow to
have a better understanding of the results overall.

## E. Communicating Results

After the visualisation and their respective interpretation are complete, the results should be
communicated in a clear and concise manner. Some ways to do this are:

### Infographics/Posters

Infographics in provide the ability to collect and collate the visualisations in an appealing and
colourful manner. It illustrates and summarizes all important information into one file.

### PowerPoint Presentation

A PowerPoint presentation would be a good alternative. A set of slides to illustrate and concisely
present the information would draw attention to the important points.

### Detailed report of the findings

A detailed report is a good supplement to the above two methods. While the first two methods
simplify the findings, a detailed report presents the information in its entirety.

## Conclusion

This report outlines in detail the methodology for UX testing, which includes in-person and online
testing. It also covers other important aspects such as ethical concerns, data processing, analysis
and visualization.

It is important to note, however, that this testing proposal is written while DreamBig is still at a
relatively early development stage. As the development progresses, many features may be added or
changed which were not considered in this report. It is thus important to continuously review and
update the testing plan to ensure it stays relevant to the prototype and their features.

Nevertheless, it is hoped that this testing plan serves as a clear guideline on how the prototype
evaluation for DreamBig would be conducted and provides clarity surrounding the process.
